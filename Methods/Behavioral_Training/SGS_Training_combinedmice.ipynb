{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcfbaf1",
   "metadata": {},
   "source": [
    "# Single Glomerular Stimulation Detection Training\n",
    "\n",
    "*_This code contains may artifacts from prior iterations and therefore isn't the most efficient._\n",
    "\n",
    "This code produces a plot which shows all of the training sessions for all of the mice combined. Specifically, the plot produced shows the mouse's detection rate accross multiple sessions until the mouse learns the task.\n",
    "\n",
    "### Note on the input data files\n",
    "\n",
    "The input to this code is a list of H5 files which were output after every session was performed. The nomenclature of these H5 files follow the following example format:\n",
    "\n",
    "mouse0070_sess01_3750V_D231016.h5\n",
    "\n",
    "Here, 0070 is the mouse number, 01 is the session number, 3750V indicates that 3.75V were applied to the AOM which modulates the stimulation laser's power, and the date of the session follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdbdfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0703a0",
   "metadata": {},
   "source": [
    "### Create a sting of mouse labels which will help us reference the necessary H5 files.\n",
    "The names of the behavioral H5 files contain the labels of the mice which underwent training ie. mouseXXXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "675e0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_patterns = [\"*mouse0691*.h5\", \"*mouse0070*.h5\", \"*mouse0071*.h5\", \"*mouse0721*.h5\", \"*mouse0722*.h5\", \"*mouse0773*.h5\", \"*mouse0781*.h5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35489803",
   "metadata": {},
   "source": [
    "Here I am setting up variables which will be used in the subsequent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08ecf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_SUCCESS_plot = []\n",
    "mouse = []\n",
    "n_stim_sess = []\n",
    "n_blank_sess = []\n",
    "frac_SUCCESS_stim = []\n",
    "frac_SUCCESS_blank = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759bea2",
   "metadata": {},
   "source": [
    "Start a loop through the mouse labels and reference the H5 files in the **directory** which contain those mouse labels. The **home_directory** is where you will later save the files to in a created folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f68d97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for string_pattern in string_patterns:\n",
    "\n",
    "    home_directory = 'C:/Users/Ekaterina/Dropbox/NYU/SingleGlomStim/Behavior_SingleGlomStim'\n",
    "    directory = 'C:/Users/Ekaterina/Dropbox/NYU/SingleGlomStim/Blank Single Glom/Training'\n",
    "\n",
    "    file_list = os.listdir(directory)\n",
    "    \n",
    "    # Extract 'XXXX' from the string 'mouseXXXX' in string_patterns\n",
    "    match = re.search(r'mouse(\\d+)', string_pattern)\n",
    "    mouse_number = match.group(1)\n",
    "    mouse.append(mouse_number)\n",
    "    \n",
    "    file_paths = glob.glob(os.path.join(directory, string_pattern))\n",
    "    file_paths = [path.replace(\"\\\\\", \"/\") for path in file_paths]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cd8ae",
   "metadata": {},
   "source": [
    "### Sort files in _file_paths_ by session number\n",
    "The session number is also included in the title of the H5 behavioral file. Specifically, the session number is indicated by XX in sessXX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "686e1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sort_key(file_path):\n",
    "       # Extract the 4 digits preceding \"V_\"\n",
    "       start_index = file_path.find(\"sess\") + 4\n",
    "       end_index = start_index + 2\n",
    "       number_str = file_path[start_index:end_index]\n",
    "       \n",
    "       # Convert the number string to an integer\n",
    "       try:\n",
    "           number = int(number_str)\n",
    "       except ValueError:\n",
    "           number = 0\n",
    "       \n",
    "       return number\n",
    "    \n",
    "    sorted_files_sess = sorted(file_paths, key=sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adaf6e",
   "metadata": {},
   "source": [
    "Create a list of dataframes called **data** using the various file_paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c45e9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = []\n",
    "    \n",
    "    for file_path in sorted_files_sess:\n",
    "        with h5py.File(file_path, 'r') as h5_file:\n",
    "            dataset = h5_file['Trials']\n",
    "            data_frame = pd.DataFrame(dataset[:]) \n",
    "            data.append(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5ef62",
   "metadata": {},
   "source": [
    "### Select the range of trials that you would like to consider for each dataframe in 'data'\n",
    "\n",
    "Mice are imperfect. It typically takes them approximately 25 to 50 trials in a session to get reacclimated to the task. Then, at one point, they will abruptly stop doing the task correctly, followed shortly by a recovery. For this reason, I introduced this step. Here, for every mouse's session, you are able to slice the session (or dataframe in **data**) into the segments that you would like to consider in calculating the mouse's detection rate. \n",
    "\n",
    "If there are two numbers listed in a slicing range, they act as the start and end of the session. If there are four numbers listed in the slicing range, this indicates that the session has an additional range cut from its middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92c691c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    slicing_ranges = []\n",
    "        \n",
    "    if mouse_number == '0691':    \n",
    "        slicing_ranges = [(20,250),  #sess01 23.09.07\n",
    "                          (20,250),  #sess02 23.09.12\n",
    "                          (100,250), #sess03 23.09.13\n",
    "                          (40,110,130,260),  #sess04 23.09.14\n",
    "                          (0,265),   #sess05 23.09.15\n",
    "                          (60,230)]  #sess06 23.09.19\n",
    "        \n",
    "    if mouse_number == '0070':    \n",
    "        slicing_ranges = [(50,300),  #sess01 23.10.16\n",
    "                          (50,300),  #sess02 23.10.17\n",
    "                          (100,250), #sess03 23.10.18\n",
    "                          (50,225),  #sess04 23.10.19\n",
    "                          (180,400), #sess05 23.10.20\n",
    "                          (180,390), #sess06 23.10.23\n",
    "                          (50,360),  #sess07 23.10.24\n",
    "                          (20,150)]  #sess08 23.11.02\n",
    "        \n",
    "    if mouse_number == '0071':    \n",
    "        slicing_ranges = [(50,300),  #sess01 23.10.16\n",
    "                          (50,300),  #sess02 23.10.17\n",
    "                          (50,300),  #sess03 23.10.18\n",
    "                          (150,300), #sess04 23.10.19\n",
    "                          (50,400),  #sess05 23.10.20\n",
    "                          (30,320)]  #sess06 23.10.23\n",
    "        \n",
    "    if mouse_number == '0721':    \n",
    "        slicing_ranges = [(50,400),  #sess01 24.02.12\n",
    "                          (50,300),  #sess02 24.02.13\n",
    "                          (50,350),  #sess03 24.02.14\n",
    "                          (50,370),  #sess04 24.02.15\n",
    "                          (40,110),  #sess05 24.02.21\n",
    "                          (50,250)]  #sess06 24.02.22                     \n",
    "    \n",
    "    if mouse_number == '0722':    \n",
    "        slicing_ranges = [(50,175),  #sess01 24.02.12\n",
    "                          (50,220),  #sess02 24.02.13\n",
    "                          (40,200),  #sess03 24.02.14\n",
    "                          (50,370),  #sess04 24.02.15\n",
    "                          (100,300), #sess05 24.02.26\n",
    "                          (150,400), #sess06 24.02.27\n",
    "                          (25,180)]  #sess07 24.02.28\n",
    "    \n",
    "    if mouse_number == '0773':    \n",
    "        slicing_ranges = [(50,300),  #sess01 24.08.13\n",
    "                          (50,500),  #sess02 24.08.14\n",
    "                          (50,600),  #sess03 24.08.15\n",
    "                          (50,500),  #sess04 24.08.16\n",
    "                          (50,400),  #sess05 24.08.19\n",
    "                          (50,145)]  #sess06 24.08.20\n",
    "\n",
    "        \n",
    "    if mouse_number == '0781':    \n",
    "        slicing_ranges = [(20,120),  #sess01 24.08.14\n",
    "                          (20,120),  #sess02 24.08.15\n",
    "                          (50,450),  #sess03 24.08.16\n",
    "                          (50,600),  #sess04 24.08.19\n",
    "                          (50,550),  #sess05 24.08.20\n",
    "                          (50,225),  #sess06 24.08.21\n",
    "                          (25,225),  #sess07 24.08.22\n",
    "                          (50,400)]  #sess11 24.08.28\n",
    "                              \n",
    "    \n",
    "    # Apply the slicing to each dataframe in the 'data' list\n",
    "    for i, ranges in enumerate(slicing_ranges):\n",
    "        if len(ranges) == 2:\n",
    "            start_idx, end_idx = ranges\n",
    "            data[i] = data[i].loc[start_idx:end_idx]\n",
    "        elif len(ranges) == 4:\n",
    "            start_idx1, end_idx1, start_idx2, end_idx2 = ranges\n",
    "            data[i] = pd.concat([data[i].loc[start_idx1:end_idx1], data[i].loc[start_idx2:end_idx2]]) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76204351",
   "metadata": {},
   "source": [
    "### Remove trials where 'pavlov'= 1\n",
    "\n",
    "Each dataframe attributed to each session in **data** contains a column titled 'pavlov'. When this column is set to 1, it means that that trial was a Go trial which was probabilistically rewarded. Meaning, whether the mouse decided to lick or not, a reward was administed to associate the reward with the stimulus. 'pavlov' is usually set to a higher percentage the 1st training session and is then exponentially tapered down. Regardless, you do not want to include gauranteed rewarded trials in your detection statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ae2b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ekaterina\\AppData\\Local\\Temp\\ipykernel_16616\\4153070405.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df[df['pavlov'] == 1].index, inplace=True) # inplace=True : ensures that changes are made directly in the original dataframes.\n"
     ]
    }
   ],
   "source": [
    "    for df in data:\n",
    "        df.drop(df[df['pavlov'] == 1].index, inplace=True) # inplace=True : ensures that changes are made directly in the original dataframes. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e0972",
   "metadata": {},
   "source": [
    "### Naming variables from '**data**'\n",
    "\n",
    "_trialtype_, _isOdor_, _isLight_, _result_, _mask_id_ are all lists of arrays. Each array stores the relevanat column from each session (dataframe) in the **data** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55ffbd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_stim  n_blank\n",
      "0       0       17\n",
      "1       0       18\n",
      "2      97      199\n",
      "3     170      319\n",
      "4     196      305\n",
      "5      87       89\n",
      "6     101      100\n",
      "7     172      179\n"
     ]
    }
   ],
   "source": [
    "    trialtype = [df['trialtype'].values for df in data]\n",
    "    # iterates over each dataframe in the \"data\" list. For each dataframe, it \n",
    "    # accesses the 'trialtype' column using df['trialtype'] and retrieves its values \n",
    "    # using the .values attribute.\n",
    "\n",
    "    result = [df['result'].values for df in data]\n",
    "    # result stores the mouse's response to the stimulus as an integer from 1 to 6\n",
    "    # Right_CO\n",
    "    # Left_CO\n",
    "    # Right_FA\n",
    "    # Left_FA\n",
    "    # Right _MISS\n",
    "    # Left_MISS\n",
    "\n",
    "    mask_id = [df['mask_id'].values for df in data]\n",
    "    # mask_id is the pattern that was presented to the mouse drawn on the DMD. \n",
    "    # For example, for the SGS application, there should only be two values in mask_id: 0 & 99\n",
    "    # 0 is the region of interest or ROI drawn over the single glomerulus which you are stimulating.\n",
    "    # 99 is the ROI drawn small in the corner of the imaging frame presented during Blank trials\n",
    "    \n",
    "    \n",
    "    # Create empty arrays to store the sums\n",
    "    n_stim = []\n",
    "    n_blank = []\n",
    "    \n",
    "    for a in mask_id:\n",
    "    # Count occurrences of 99 (stimulus) and 0 (blank)\n",
    "        n_stim_count = np.sum(a == 0)\n",
    "        n_blank_count = np.sum(a == 99)\n",
    "\n",
    "    # Append counts to the respective arrays\n",
    "        n_stim.append(n_stim_count)\n",
    "        n_blank.append(n_blank_count)\n",
    "\n",
    "    # Convert the lists to NumPy arrays if needed\n",
    "    n_stim = np.array(n_stim)\n",
    "    n_blank = np.array(n_blank)\n",
    "    length_sess = n_stim + n_blank\n",
    "    # Append n_stim and n_blank arrays for the current string_pattern\n",
    "    n_stim_sess.append(n_stim)\n",
    "    n_blank_sess.append(n_blank)\n",
    "   \n",
    "    # Ensure that tot_trials_sess will store the element-wise sum of n_stim_sess and n_blank_sess\n",
    "    tot_trials_sess = []\n",
    "    \n",
    "    # Loop through the lists of arrays (n_stim_sess and n_blank_sess)\n",
    "    for stim_array, blank_array in zip(n_stim_sess, n_blank_sess):\n",
    "        # Ensure both arrays have the same shape before adding\n",
    "        if stim_array.shape == blank_array.shape:\n",
    "            combined_array = stim_array + blank_array  # Element-wise sum\n",
    "            tot_trials_sess.append(combined_array)     # Append the result\n",
    "    \n",
    "    # number of sessions conducted\n",
    "    n_sessions = len(data)\n",
    "    \n",
    "    n_stim = np.array([len(arr) - np.sum(arr) for arr in trialtype])\n",
    "    n_blank = np.array([np.sum(arr) for arr in trialtype])\n",
    "    n_trialtype = pd.DataFrame({'n_stim': n_stim, 'n_blank': n_blank})\n",
    "    print(n_trialtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39d27e",
   "metadata": {},
   "source": [
    "**n_trialtype** outlines how many stimulation (Go) and blank (NoGo) trials were in each session for the current mouse being looped over. You may notice that for the first couple of sessions, the number of stimulation or **n_stim** trials was 0. This is because for those trials, _pavlov_ was set to 1 for the selected slice range and we removed all trials for which pavlov == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba028b",
   "metadata": {},
   "source": [
    "Calculate the success detection rate for Go & NoGo trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "147e8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 99]\n"
     ]
    }
   ],
   "source": [
    "    # Convert numpy arrays to pandas DataFrames\n",
    "    mask_id_df = [pd.DataFrame(df) if isinstance(df, np.ndarray) else df for df in mask_id]\n",
    "    \n",
    "    # Concatenate all dataframes into a single dataframe or series\n",
    "    concatenated_data = pd.concat(mask_id_df, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicate values and sort in numerical order\n",
    "    ROI_values = sorted(concatenated_data[0].unique())\n",
    "    \n",
    "    # Number of regions of interest (ROIs)\n",
    "    n_ROIs = len(ROI_values)\n",
    "    # 2\n",
    "    \n",
    "    # Print all indeces present in mask_id\n",
    "    print(ROI_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38e306",
   "metadata": {},
   "source": [
    "Sum how many times each mask_id is present in each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a2dc306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    99\n",
      "1    0   17\n",
      "2    0   18\n",
      "3   97  199\n",
      "4  170  319\n",
      "5  196  305\n",
      "6   87   89\n",
      "7  101  100\n",
      "8  172  179\n"
     ]
    }
   ],
   "source": [
    "    number_counts = {number: [] for number in ROI_values}\n",
    "    \n",
    "    # Iterate through each DataFrame in 'mask_id'\n",
    "    for df in mask_id_df:\n",
    "        if 'Numbers' in df.columns:\n",
    "            column_name = 'Numbers'\n",
    "        else:\n",
    "            column_name = df.columns[0]  # Get the column name dynamically\n",
    "    \n",
    "        for number in ROI_values:\n",
    "            count = df[column_name].eq(number).sum()\n",
    "            number_counts[number].append(count)\n",
    "    \n",
    "    # This df contains columns with ROI indeces and rows that store the number of times each ROI was presented for each voltage\n",
    "    ROI_sum_df = pd.DataFrame(number_counts, index=range(1, len(mask_id)+1))\n",
    "\n",
    "    print(ROI_sum_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730d2a0",
   "metadata": {},
   "source": [
    "### Tabulate the Success rates of the 2 ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c2b32",
   "metadata": {},
   "source": [
    "First, create dictionary _SUC_ROI_dict_ to store the successful trials per session for each ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90e9d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of successful trilas for each 'mask_id' by looping through the ROIs listed in 'mask_id_values'\n",
    "for value in ROI_values:\n",
    "    var_name = f\"SUC_ROI_{value:02}\"\n",
    "    locals()[var_name] = [[] for _ in range(n_sessions)]\n",
    "    \n",
    "# Create a dictionary to store the lists of successful trials for each ROI\n",
    "SUC_ROI_dict = {value: [[] for _ in range(n_sessions)] for value in ROI_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbd39c",
   "metadata": {},
   "source": [
    "Then, find successful Blank trials for each session.\n",
    "* For blank trials (mask_id = 99), a correct mouse response is to withold its lick (result = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3686737",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(n_sessions):\n",
    "        for x in range(len(trialtype[i])):         \n",
    "                \n",
    "                if mask_id[i][x] == 99 and result[i][x] == 1:\n",
    "                    SUC_ROI_dict[99][i].append(1)\n",
    "                    \n",
    "                if mask_id[i][x] == 99 and result[i][x] != 1:\n",
    "                    SUC_ROI_dict[99][i].append(0)\n",
    "                \n",
    "                if mask_id[i][x] != 99:\n",
    "                    SUC_ROI_dict[99][i].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3e256",
   "metadata": {},
   "source": [
    "Now find the successful Stim trials for each session.\n",
    "* For stim trials (mask_id = 0), a correct mouse response is to lick (result =2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6bb58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ROI_values_stim = [value for value in ROI_values if value != 99]\n",
    "    keys_no_99 = [key for key in SUC_ROI_dict.keys() if key != 99]\n",
    "    \n",
    "    \n",
    "    for i in range(n_sessions):\n",
    "        for x in range(len(trialtype[i])):\n",
    "            for v in ROI_values_stim:\n",
    "                \n",
    "                if result[i][x] != 2:\n",
    "                    SUC_ROI_dict[v][i].append(0)\n",
    "    \n",
    "                if mask_id[i][x] == v and result[i][x] == 2:\n",
    "                    SUC_ROI_dict[v][i].append(1)\n",
    "                            \n",
    "                if mask_id[i][x] != v and result[i][x] == 2:\n",
    "                    SUC_ROI_dict[v][i].append(0)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc399287",
   "metadata": {},
   "source": [
    "Sum the number of successful Blank and Stim trials in each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc5e00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sum_SUC_ROI_dict = {}\n",
    "    \n",
    "    for key, binary_lists in SUC_ROI_dict.items():\n",
    "        sum_lists = [sum(binary_list) for binary_list in binary_lists]\n",
    "        sum_SUC_ROI_dict[key] = sum_lists\n",
    "    \n",
    "    \n",
    "    # Convert the dictionary into a DataFrame\n",
    "    sum_SUC_ROI_df = pd.DataFrame(sum_SUC_ROI_dict, index=range(1, len(mask_id)+1))\n",
    "                \n",
    "    # Fraction of successful trials for each ROI\n",
    "    frac_SUCCESS_ROI = sum_SUC_ROI_df/ROI_sum_df\n",
    "    \n",
    "    # Array of fraction of successful trials for Blanks (mask_id = 99)\n",
    "    frac_SUCCESS_Blanks = frac_SUCCESS_ROI[99].to_numpy()\n",
    "    \n",
    "    # Array of fraction of successful trials for Blanks (mask_id = 0)\n",
    "    frac_SUCCESS_Stim = frac_SUCCESS_ROI[0].to_numpy()\n",
    "    # This line of code replaces the NaN values in frac_SUCCESS_Stim with zeros\n",
    "    # NaN values are there bc for two sessions for one of the mice, there were no Stim trials without the use of pavlov.\n",
    "    frac_SUCCESS_Stim = np.nan_to_num(frac_SUCCESS_Stim, nan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e760dc8",
   "metadata": {},
   "source": [
    "Find the success rate of all ROI's combined (0 : Stim and 99 : Blank trials) by averaging their individual success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    avg_SUCCESS_frac = (frac_SUCCESS_Stim + frac_SUCCESS_Blanks) / 2.0\n",
    "    \n",
    "    # This line of code is meant to append the success rate arrays of various other mice.\n",
    "    avg_SUCCESS_plot.append(avg_SUCCESS_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e8b0b",
   "metadata": {},
   "source": [
    "## Calculate the confidence interval of each session\n",
    "\n",
    "Calculate 95% confidence interval [METHOD](https://www.dummies.com/article/academics-the-arts/science/biology/the-confidence-interval-around-a-proportion-149351/) for each session which will account for the number of trials being considered for each session. \n",
    "\n",
    "To calculate the Standard Error (_SE_) for each value in **avg_SUCCESS_plot** (which corresponds to _p_ in the equation) using the values in **tot_trials_sess** (which corresponds to _N_), we can loop through each element of both **avg_SUCCESS_plot** and **tot_trials_sess**. The formula for the _SE_ is:\n",
    "\n",
    "_SE = sqrt(p(1-p)/N)_\n",
    "\n",
    "This equation should be applied to each element in **avg_SUCCESS_plot** (_p_) and **tot_trials_sess** (_N_) and the output should be stored in **SE_plot**.\n",
    "Then, multiply the _SE_ by a preselected k-value to calculate the 95% confidence interval: **CI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constant k for calculating the confidence interval\n",
    "k = 1.96\n",
    "# k is 1.96 for normal-based 95 percent confidence limits.\n",
    "\n",
    "# Initialize CI to store the calculated confidence intervals\n",
    "CI = []\n",
    "\n",
    "# Loop over the avg_SUCCESS_plot (p) and tot_trials_sess (N) lists\n",
    "for avg_success_array, tot_trials_array in zip(avg_SUCCESS_plot, tot_trials_sess):\n",
    "    # Create an array to store the confidence intervals for the current session\n",
    "    ci_array = []\n",
    "    \n",
    "    # Loop over each value of p and N in the current arrays\n",
    "    for p, N in zip(avg_success_array, tot_trials_array):\n",
    "        # Calculate the standard error using the given formula\n",
    "        if N > 0:  # Ensure N is positive to avoid division by zero\n",
    "            SE = np.sqrt(p * (1 - p) / N)\n",
    "        else:\n",
    "            SE = 0  # Handle cases where N is zero\n",
    "        \n",
    "        # Multiply by the scaling factor k = 1.96 to get the confidence interval\n",
    "        CI_value = SE * k\n",
    "        \n",
    "        # Append the CI value to the array\n",
    "        ci_array.append(CI_value)\n",
    "    \n",
    "    # Append the CI array for this session to CI\n",
    "    CI.append(ci_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9dc959",
   "metadata": {},
   "source": [
    "Create the **confidence_intervals** list of arrays, where each element is an array of two values (upper and lower bounds) for each corresponding value in **avg_SUCCESS_plot** and **CI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    confidence_intervals = []\n",
    "\n",
    "    # Loop through each session in avg_SUCCESS_plot and CI\n",
    "    for avg_success_array, ci_array in zip(avg_SUCCESS_plot, CI):\n",
    "        # Create an array to store confidence intervals for the current session\n",
    "        session_confidence_intervals = []\n",
    "        \n",
    "        # Loop through each p-value in avg_SUCCESS_array and its corresponding CI value\n",
    "        for p, ci in zip(avg_success_array, ci_array):\n",
    "            # Calculate the upper and lower bounds of the confidence interval\n",
    "            upper_bound = p + ci\n",
    "            lower_bound = p - ci\n",
    "            \n",
    "            # Store the upper and lower bounds as an array [upper_bound, lower_bound]\n",
    "            session_confidence_intervals.append([upper_bound, lower_bound])\n",
    "        \n",
    "        # Append the confidence intervals for this session to the main list\n",
    "        confidence_intervals.append(session_confidence_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381bc97a",
   "metadata": {},
   "source": [
    "## Plot the success rate accross sessions for all mice during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a023678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure with one subplot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "\n",
    "# Get the maximum length of the sublists in avg_SUCCESS_plot to set x-axis limits\n",
    "max_x_length = max(len(sublist) for sublist in avg_SUCCESS_plot)\n",
    "\n",
    "# Loop through avg_SUCCESS_plot and plot each list for each mouse\n",
    "for i, sublist in enumerate(avg_SUCCESS_plot):\n",
    "    x = np.arange(len(sublist)) + 1  # x-axis values (session numbers)\n",
    "    \n",
    "    # Plot the data points and capture the color of the line\n",
    "    line, = ax.plot(x, sublist, 'o-', label=f'Mouse {mouse[i]}', alpha=0.7)\n",
    "    line_color = line.get_color()  # Get the color of the current line\n",
    "\n",
    "    # Extract the confidence intervals for the current session\n",
    "    confidence_interval_array = confidence_intervals[i]\n",
    "    \n",
    "    # Separate the upper and lower bounds from confidence_interval_array\n",
    "    lower_bounds = [ci[1] for ci in confidence_interval_array]\n",
    "    upper_bounds = [ci[0] for ci in confidence_interval_array]\n",
    "\n",
    "    # Plot the shaded error region for the confidence interval\n",
    "    ax.fill_between(x, lower_bounds, upper_bounds, color=line_color, alpha=0.3)\n",
    "\n",
    "# Add dashed lines at y = 0.0, 0.5, and 1.0 for reference\n",
    "ax.axhline(y=0.0, color='gray', linestyle='--', linewidth=0.8)\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=0.8)\n",
    "ax.axhline(y=1.0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Set labels, title, and axis limits\n",
    "ax.set_title(f'Training Single Glomerular Stimulation Detection', fontsize=16)\n",
    "ax.set_ylabel('Fraction of Successful Trials', fontsize=14)\n",
    "ax.set_xlabel('Session Number', fontsize=14)\n",
    "ax.set_ylim(0.4, 1.1)  # Adjust y-axis limits for clarity\n",
    "ax.set_xlim(0.5, max_x_length + 0.5)  # Set x-axis limits\n",
    "ax.set_xticks(np.arange(1, max_x_length + 1))  # Ensure x-ticks match session numbers\n",
    "ax.legend(loc='lower right', fontsize='large')  # Add a legend for the mice\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49758110",
   "metadata": {},
   "source": [
    "### Save the produced plots\n",
    "\n",
    "This code with save the produced plot to a created folder in the **home_directory** which you specified at the beginning of the code. Specifically it will create a new folder in your home directory called _plots_behavior_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure as a .png file in the specified directory\n",
    "save_directory = os.path.join(home_directory, 'plots_behavior')\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Define the full path for the plot\n",
    "save_path = os.path.join(save_directory, f'SGS_Training_combinedmice.png')\n",
    "\n",
    "# Save the plot\n",
    "fig.savefig(save_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2da1d6",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
